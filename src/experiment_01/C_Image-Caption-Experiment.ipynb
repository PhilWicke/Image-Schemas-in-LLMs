{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision-Language Model\n",
    "\n",
    "* 4bit quantised idefics-80b VLM\n",
    "* 4bit quantised idefics-80b VLM with instruction-tuning\n",
    "\n",
    "*use `idefics_colab` conda env*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/pwicke/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mounts/work/pwicke/miniconda3/envs/idefics_colab/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:206: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 17/17 [03:53<00:00, 13.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import IdeficsForVisionText2Text, AutoProcessor, BitsAndBytesConfig\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Check available gpu (gpustat -i)\n",
    "device = 7\n",
    "\n",
    "# checkpoint = \"HuggingFaceM4/tiny-random-idefics\"\n",
    "local_path = \"/mounts/data/corp/huggingface/\"\n",
    "checkpoint = local_path+\"idefics/idefics-80b\"\n",
    "\n",
    "# Here we skip some special modules that can't be quantized properly\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    llm_int8_skip_modules=[\"lm_head\", \"embed_tokens\"],\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(checkpoint, use_auth_token=True)\n",
    "# Simply take-off the quantization_config arg if you want to load the original model\n",
    "model = IdeficsForVisionText2Text.from_pretrained(checkpoint,quantization_config=bnb_config, device_map={\"\":device}) #  quantization_config=bnb_config,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inference(model, processor, prompts, max_new_tokens=50):\n",
    "    tokenizer = processor.tokenizer\n",
    "    bad_words = [\"<image>\", \"<fake_token_around_image>\"]\n",
    "    if len(bad_words) > 0:\n",
    "        bad_words_ids = tokenizer(bad_words, add_special_tokens=False).input_ids\n",
    "\n",
    "    eos_token = \"</s>\"\n",
    "    eos_token_id = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "\n",
    "    inputs = processor(prompts, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(**inputs, eos_token_id=[eos_token_id], bad_words_ids=bad_words_ids, max_new_tokens=max_new_tokens, early_stopping=True)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image A: Image B: Image C: Image D: Question: Which one of the images (A-D) describes the event 'arrow down' best? Answer: Image A\n",
      "\n",
      "Question\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for i in range(1,5):\n",
    "    img_path = \"../../data/direction0\"+str(i)+\".png\"\n",
    "    images.append(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "prompts = [\n",
    "    # \"Instruction: provide an answer to the question. Use the image to answer.\\n\",\n",
    "    \"Image A:\",\n",
    "    images[0],\n",
    "    \"Image B:\",\n",
    "    images[1],\n",
    "    \"Image C:\",\n",
    "    images[2],\n",
    "    \"Image D:\",\n",
    "    images[3],\n",
    "    \"Question: Which one of the images (A-D) describes the event 'arrow down' best? Answer:\"\n",
    "]\n",
    "check_inference(model, processor, prompts, max_new_tokens=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image A: Image B: Image C: Image D: Question: Give a one sentence description for each image. The description should focus on the differences. Answer:\n",
      "\n",
      "Image A: The object is moving to the right.\n",
      "\n",
      "Image B: The object is moving to the left.\n",
      "\n",
      "Image C: The object is moving up and down.\n",
      "\n",
      "Image D: The object is moving up and down.\n",
      "\n",
      "Question: What is the difference\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for i in range(1,5):\n",
    "    img_path = \"../../data/direction0\"+str(i)+\".png\"\n",
    "    images.append(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "prompts = [\n",
    "    # \"Instruction: provide an answer to the question. Use the image to answer.\\n\",\n",
    "    \"Image A:\",\n",
    "    images[0],\n",
    "    \"Image B:\",\n",
    "    images[1],\n",
    "    \"Image C:\",\n",
    "    images[2],\n",
    "    \"Image D:\",\n",
    "    images[3],\n",
    "    \"Question: Give a one sentence description for each image. The description should focus on the differences. Answer:\"\n",
    "]\n",
    "check_inference(model, processor, prompts, max_new_tokens=60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idefics_colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
