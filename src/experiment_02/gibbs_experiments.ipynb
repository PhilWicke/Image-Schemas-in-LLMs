{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "import re\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "api_key = open('openai.key', 'r').read()\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Preperation and Helper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description from paper: \n",
    "- The participants in this study were first asked to stand up and focus on different aspects of their bodily experience of standing in the same way as did participants in Experiment 1.\n",
    "- Following this, we introduced the five image schemas of BALANCE, VERTICALITY, CENTER-PERIPHERY, RESISTANCE, and LINKAGE as was done in Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = {\n",
    "    \"VERTICALITY\": \"Consider the notion of VERTICALITY. Verticality refers to the sense of an extension along an up—down orientation.\",\n",
    "    \"BALANCE\": \"Consider the notion of BALANCE. Balance refers to your sense of symmetry or stability relative to some point within your body.\",\n",
    "    \"CENTER-PERIPHERY\": \"Consider the notion of CENTER-PERIPHERY. Center-periphery refers to the experience of some objects or events as central while surrounding objects and events are peripheral or to the outside.\",\n",
    "    \"LINKAGE\": \"Consider the notion of LINKAGE. Linkage refers to the perception of a connection between objects or events.\",\n",
    "    \"RESISTANCE\": \"Consider the notion of RESISTANCE. Resistance refers to the experience of your body opposing some external force.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "exp_3_df = pd.read_csv('../../data/Gibbs_Exp3.csv', sep=';')\n",
    "# drop nan rows\n",
    "exp_3_df = exp_3_df.dropna()\n",
    "exp_4_df = pd.read_csv('../../data/Gibbs_Exp4.csv', sep=';')\n",
    "stimuli_exp3 = exp_3_df['Stimulus'].values\n",
    "stimuli_exp4 = exp_4_df['Stimulus'].values\n",
    "print(len(stimuli_exp3))\n",
    "print(len(stimuli_exp4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompts\n",
    "prompts_exp3 = {\"VERTICALITY\":[], \"BALANCE\":[], \"CENTER-PERIPHERY\":[], \"LINKAGE\":[], \"RESISTANCE\":[]}\n",
    "prompts_exp4 = {\"VERTICALITY\":[], \"BALANCE\":[], \"CENTER-PERIPHERY\":[], \"LINKAGE\":[], \"RESISTANCE\":[]}\n",
    "\n",
    "\n",
    "for i in range(len(stimuli_exp3)):\n",
    "    prompt_ending =  \"How strongly is the phrase ''\" + stimuli_exp3[i] + \"'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\"\n",
    "    prompts_exp3[\"VERTICALITY\"].append(definitions[\"VERTICALITY\"] + \"\\n\" + prompt_ending)\n",
    "    prompts_exp3[\"BALANCE\"].append(definitions[\"BALANCE\"] + \"\\n\" + prompt_ending)\n",
    "    prompts_exp3[\"CENTER-PERIPHERY\"].append(definitions[\"CENTER-PERIPHERY\"] + \"\\n\" + prompt_ending)\n",
    "    prompts_exp3[\"LINKAGE\"].append(definitions[\"LINKAGE\"] + \"\\n\" + prompt_ending)\n",
    "    prompts_exp3[\"RESISTANCE\"].append(definitions[\"RESISTANCE\"] + \"\\n\" + prompt_ending)\n",
    "\n",
    "for i in range(len(stimuli_exp4)):\n",
    "    prompt_ending =  \"How strongly is the phrase ''\" + stimuli_exp4[i] + \"'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\"\n",
    "    prompts_exp4[\"VERTICALITY\"].append(definitions[\"VERTICALITY\"] + \"\\n\" + prompt_ending)\n",
    "    prompts_exp4[\"BALANCE\"].append(definitions[\"BALANCE\"] + \"\\n\" + prompt_ending)\n",
    "    prompts_exp4[\"CENTER-PERIPHERY\"].append(definitions[\"CENTER-PERIPHERY\"] + \"\\n\" + prompt_ending)\n",
    "    prompts_exp4[\"LINKAGE\"].append(definitions[\"LINKAGE\"] + \"\\n\" + prompt_ending)\n",
    "    prompts_exp4[\"RESISTANCE\"].append(definitions[\"RESISTANCE\"] + \"\\n\" + prompt_ending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variants with which GPT can be prompted to generate the questionnaire answers\n",
    "def gpt_complete(prompt, model):\n",
    "    temperature = 0\n",
    "    return openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=100,\n",
    "        temperature=temperature\n",
    "    ) \n",
    "\n",
    "def gpt_complete_proba(prompt, model):\n",
    "    # get the probability distribution over the next token for the tokens 1, 2, 3, 4, 5, 6, 7\n",
    "    temperature = 0\n",
    "    results = []\n",
    "    debug = []\n",
    "    for i in range(1, 8):\n",
    "        next_prompt = prompt + \"\\n\\n\"+ str(i)\n",
    "        print(next_prompt)\n",
    "        result = openai.Completion.create(\n",
    "            model=model,\n",
    "            prompt=next_prompt,\n",
    "            max_tokens=1,\n",
    "            temperature=temperature,\n",
    "            logprobs=1,\n",
    "            echo=True\n",
    "        )\n",
    "        debug.append(result)\n",
    "        #print(result)\n",
    "        # the index of i in the list of tokens\n",
    "        index = result[\"choices\"][0][\"logprobs\"][\"tokens\"].index(str(i))\n",
    "        print(index)\n",
    "        print(result[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][index])\n",
    "        print(np.exp(result[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][index]))\n",
    "        print(result[\"choices\"][0][\"logprobs\"][\"tokens\"][index])\n",
    "        print()\n",
    "        log_prob_result=result[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][index]\n",
    "        prob_result = np.exp(log_prob_result)\n",
    "        results.append(prob_result)\n",
    "        # wait 20 seconds to avoid exceeding the API rate limit\n",
    "        time.sleep(21)\n",
    "    average_completion = 0\n",
    "    for i in range(1, 8):\n",
    "        average_completion += i * results[i-1]\n",
    "    average_completion = average_completion / sum(results)      # TODO: verify this is the right operation\n",
    "\n",
    "    return results, average_completion, debug\n",
    "\n",
    "\n",
    "# incomplet methods: \n",
    "def gpt_complete_reasoning(prompt, model):\n",
    "    prompt += \"Reason step by step: \\n\"\n",
    "    pass\n",
    "\n",
    "def gpt_with_history(prompt, model):\n",
    "    pass\n",
    "\n",
    "def gpt_simulate_human(prompt, model, name, gender):           # TE paradigm \n",
    "    prompt = name + \" was asked to...\" + name +\" responded with the number: \" + prompt\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Consider the notion of VERTICALITY. Verticality refers to the sense of an extension along an up—down orientation.\\nHow strongly is the phrase ''stand at attention'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example prompt\n",
    "prompts_exp3[\"VERTICALITY\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider the notion of VERTICALITY. Verticality refers to the sense of an extension along an up—down orientation.\n",
      "How strongly is the phrase ''stand at attention'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\n",
      "\n",
      "1\n",
      "60\n",
      "-19.92949\n",
      "2.2117318185277327e-09\n",
      "1\n",
      "\n",
      "Consider the notion of VERTICALITY. Verticality refers to the sense of an extension along an up—down orientation.\n",
      "How strongly is the phrase ''stand at attention'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\n",
      "\n",
      "2\n",
      "60\n",
      "-20.815136\n",
      "9.122235821808137e-10\n",
      "2\n",
      "\n",
      "Consider the notion of VERTICALITY. Verticality refers to the sense of an extension along an up—down orientation.\n",
      "How strongly is the phrase ''stand at attention'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\n",
      "\n",
      "3\n",
      "60\n",
      "-19.669903\n",
      "2.8672771090706086e-09\n",
      "3\n",
      "\n",
      "Consider the notion of VERTICALITY. Verticality refers to the sense of an extension along an up—down orientation.\n",
      "How strongly is the phrase ''stand at attention'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\n",
      "\n",
      "4\n",
      "60\n",
      "-18.385382\n",
      "1.0359291401426477e-08\n",
      "4\n",
      "\n",
      "Consider the notion of VERTICALITY. Verticality refers to the sense of an extension along an up—down orientation.\n",
      "How strongly is the phrase ''stand at attention'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\n",
      "\n",
      "5\n",
      "60\n",
      "-14.107265\n",
      "7.469519334512689e-07\n",
      "5\n",
      "\n",
      "Consider the notion of VERTICALITY. Verticality refers to the sense of an extension along an up—down orientation.\n",
      "How strongly is the phrase ''stand at attention'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\n",
      "\n",
      "6\n",
      "60\n",
      "-10.114392\n",
      "4.049257232719549e-05\n",
      "6\n",
      "\n",
      "Consider the notion of VERTICALITY. Verticality refers to the sense of an extension along an up—down orientation.\n",
      "How strongly is the phrase ''stand at attention'' related to this notion on a scale from 1 (not at all related) to 7 (very strongly related)?\n",
      "\n",
      "7\n",
      "60\n",
      "-0.00020883085\n",
      "0.9997911909536442\n",
      "7\n",
      "\n",
      "[2.2117318185277327e-09, 9.122235821808137e-10, 2.8672771090706086e-09, 1.0359291401426477e-08, 7.469519334512689e-07, 4.049257232719549e-05, 0.9997911909536442]\n",
      "6.99995794609905\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "model = \"text-davinci-003\"\n",
    "\n",
    "probas,r,d = gpt_complete_proba(prompt=prompts_exp3[\"VERTICALITY\"][0], model=model)\n",
    "print(probas)\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4693367739968185, 0.6304976189698971, 0.0021300609172966016, 0.0004053786456902955, 0.00030428463356096594, 2.8846006426974795e-05, 4.566600513491415e-06]\n",
      "1.5779979076082327\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "model = \"text-davinci-003\"\n",
    "\n",
    "probas,r,d = gpt_complete_proba(prompt=prompts_exp3[\"VERTICALITY\"][1], model=model)\n",
    "print(probas)\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][\"choices\"][0][\"logprobs\"][\"tokens\"].index(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9953776823446714\n"
     ]
    }
   ],
   "source": [
    "log_prob=c[0][\"choices\"][0][\"logprobs\"][\"token_logprobs\"][-2]\n",
    "# translate log_prob to prob\n",
    "prob = np.exp(log_prob)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the Data with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for default-text-davinci-003 in organization org-3JxRZ6OWspj2q2bxuxmCUL9a on requests per day. Limit: 200 / day. Please try again in 7m12s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bv/9t03hlvd6jv_vzfmf4gqhkfm0000gn/T/ipykernel_2846/79837651.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstimuli_exp3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompletions_exp3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mcompletions_exp3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpt_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts_exp3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bv/9t03hlvd6jv_vzfmf4gqhkfm0000gn/T/ipykernel_2846/3731520895.py\u001b[0m in \u001b[0;36mgpt_complete\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgpt_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     return openai.Completion.create(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    113\u001b[0m         )\n\u001b[1;32m    114\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         )\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             return (\n\u001b[0;32m--> 328\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    329\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 ),\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    362\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for default-text-davinci-003 in organization org-3JxRZ6OWspj2q2bxuxmCUL9a on requests per day. Limit: 200 / day. Please try again in 7m12s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
     ]
    }
   ],
   "source": [
    "model = \"text-davinci-003\"\n",
    "completions_exp3 = {\"VERTICALITY\": [], \"BALANCE\": [], \"CENTER-PERIPHERY\": [], \"LINKAGE\": [], \"RESISTANCE\": []}\n",
    "\n",
    "for i in range(len(stimuli_exp3)):\n",
    "    for k in completions_exp3:\n",
    "        completions_exp3[k].append(gpt_complete(prompts_exp3[k][i], model))\n",
    "        time.sleep(30)\n",
    "\n",
    "with open('completions_exp3.pkl', 'wb') as f:\n",
    "    pickle.dump(completions_exp3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions_exp4 = {\"VERTICALITY\": [], \"BALANCE\": [], \"CENTER-PERIPHERY\": [], \"LINKAGE\": [], \"RESISTANCE\": []} \n",
    "assert len(completions_exp3) == len(completions_exp4)\n",
    "for i in range(len(stimuli_exp4)):\n",
    "    for k in completions_exp4:\n",
    "        completions_exp4[k].append(gpt_complete(prompts_exp4[k][i], model))\n",
    "        time.sleep(30)\n",
    "\n",
    "with open('completions_exp4.pkl', 'wb') as f:\n",
    "    pickle.dump(completions_exp4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only the numbers from the completions\n",
    "\n",
    "completions_exp3_clean = {\"VERTICALITY\": [], \"BALANCE\": [], \"CENTER-PERIPHERY\": [], \"LINKAGE\": [], \"RESISTANCE\": []}\n",
    "completions_exp4_clean = {\"VERTICALITY\": [], \"BALANCE\": [], \"CENTER-PERIPHERY\": [], \"LINKAGE\": [], \"RESISTANCE\": []}\n",
    "\n",
    "for k in completions_exp3:\n",
    "    for i in range(len(completions_exp3[k])):\n",
    "        clean_item = completions_exp3[k][i][\"choices\"][0][\"text\"]\n",
    "        clean_item = int(re.findall(r'\\d+', clean_item)[0])\n",
    "        completions_exp3_clean[k].append(clean_item)\n",
    "\n",
    "for k in completions_exp4:\n",
    "    for i in range(len(completions_exp4[k])):\n",
    "        clean_item = completions_exp4[k][i][\"choices\"][0][\"text\"]\n",
    "        clean_item = int(re.findall(r'\\d+', clean_item)[0])\n",
    "        completions_exp4_clean[k].append(clean_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlations for experiment 3\n",
      "Spearman correlations for experiment 4\n",
      "VERTICALITY SpearmanrResult(correlation=0.6833876221034471, pvalue=1.627063547884175e-05)\n",
      "BALANCE SpearmanrResult(correlation=0.6771840725179004, pvalue=2.0761491611577507e-05)\n",
      "CENTER-PERIPHERY SpearmanrResult(correlation=0.6901380535614554, pvalue=1.23965800957632e-05)\n",
      "LINKAGE SpearmanrResult(correlation=0.5197179828067287, pvalue=0.0022993844979337305)\n",
      "RESISTANCE SpearmanrResult(correlation=0.7058717439215124, pvalue=6.389977181110315e-06)\n"
     ]
    }
   ],
   "source": [
    "print(\"Spearman correlations for experiment 3\")\n",
    "for k in completions_exp3_clean:\n",
    "    print(k, stats.spearmanr(completions_exp3_clean[k], exp_3_df[k]))\n",
    "\n",
    "print(\"Spearman correlations for experiment 4\")\n",
    "for k in completions_exp4_clean:\n",
    "    print(k, stats.spearmanr(completions_exp4_clean[k], exp_4_df[k]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verticality Spearman R:  SpearmanrResult(correlation=0.5319115370624121, pvalue=0.001728905163310417)\n",
      "Blockage Spearman R:  SpearmanrResult(correlation=0.3889504346025759, pvalue=0.02779617841811564)\n",
      "Center-Peripher Spearman R:  SpearmanrResult(correlation=0.7397528813626304, pvalue=1.3126737552856912e-06)\n",
      "Resistance Spearman R:  SpearmanrResult(correlation=0.6820014752671762, pvalue=1.71900059033538e-05)\n",
      "Linkage Spearman R:  SpearmanrResult(correlation=0.5431252313598959, pvalue=0.0013174767080267854)\n"
     ]
    }
   ],
   "source": [
    "r_V = stats.spearmanr(completion_numbers_V, exp_3_df[\"V\"].values)\n",
    "print(\"Verticality Spearman R: \", r_V)\n",
    "\n",
    "r_B = stats.spearmanr(completion_numbers_B, exp_3_df[\"B\"].values)\n",
    "print(\"Balance Spearman R: \", r_B)\n",
    "\n",
    "r_C = stats.spearmanr(completion_numbers_C, exp_3_df[\"CP\"].values)\n",
    "print(\"Center-Peripher Spearman R: \", r_C)\n",
    "\n",
    "r_R = stats.spearmanr(completion_numbers_R, exp_3_df[\"R\"].values)\n",
    "print(\"Resistance Spearman R: \", r_R)\n",
    "\n",
    "r_L = stats.spearmanr(completion_numbers_L, exp_3_df[\"L\"].values)\n",
    "print(\"Linkage Spearman R: \", r_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Verticality: 1.8465624999999999\n",
      "MSE Balance: 1.448125\n",
      "MSE CP: 2.0453125\n",
      "MSE Resistance: 1.2834375\n",
      "MSE Linkage: 2.364375\n"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "print(\"MAE Verticality:\", mean_absolute_error(completion_numbers_V, exp_3_df['V']))\n",
    "print(\"MAE Balance:\", mean_absolute_error(completion_numbers_B, exp_3_df['B']))\n",
    "print(\"MAE CP:\", mean_absolute_error(completion_numbers_C, exp_3_df['CP']))\n",
    "print(\"MAE Resistance:\", mean_absolute_error(completion_numbers_R, exp_3_df['R']))\n",
    "print(\"MAE Linkage:\", mean_absolute_error(completion_numbers_L, exp_3_df['L']))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis\n",
    "\n",
    "We repeate the analysis from the paper but this time with the numbers generated from GPT instead of humans\n",
    "\n",
    "Problem: The paper scores can not be reproduced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis \n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1=[\"one-night stand\", \"let the mixture stand\", \"a standing ovation\", \"on the witness stand\", \"the police told them to stand back\", \"stand at attention\", \"let the issue stand\", \"stand out in several sports\", \"the boss always stands over me\", \"to stand the test of time\", \"don't stand for such treatment\"]\n",
    "cluster_2=[\"to stand in someone else's shoes\", \"the clock stands on the mantle\", \"he stands committed\", \"we stand on 30 years of experience\", \"united we stand\", \"stand on shaky ground\", \"to stand firm\", \"stand in awe\", \"to stand to profit\"]\n",
    "cluster_3=[\"stand by your man\", \"to stand accused\", \"the house stands in the clearing\", \"he stands six-foot nine\", \"the barometer stands at 30 inches\", \"to stand against great odds\", \"they did nothing but stand around\", \"the engine can't stand the constant wear\", \"the part stands for the whole\", \"it stands to reason\", \"get stood up for a date\", \"as the matter now stands\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy exp4: 0.84375\n"
     ]
    }
   ],
   "source": [
    "# LDA with GPT data \n",
    "y = []\n",
    "for s in stimuli_exp3:\n",
    "    if s in cluster_1:\n",
    "        y.append(0)\n",
    "    elif s in cluster_2:\n",
    "        y.append(1)\n",
    "    elif s in cluster_3:\n",
    "        y.append(2)\n",
    "    else:\n",
    "        print('error regarding:', s)\n",
    "\n",
    "x_exp3 = []\n",
    "x_exp4 = []\n",
    "for i in range(len(stimuli_exp4)):\n",
    "    schema_profile = []\n",
    "    for k in completions_exp4_clean:\n",
    "        schema_profile.append(completions_exp4_clean[k][i])\n",
    "    x_exp4.append(schema_profile)\n",
    "\n",
    "\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(x_exp4, y)\n",
    "y_pred4 = clf.predict(x_exp4)\n",
    "print('accuracy exp4:', accuracy_score(y_true=y, y_pred=y_pred4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy original exp3: 0.6875\n",
      "accuracy original exp4: 0.71875\n"
     ]
    }
   ],
   "source": [
    "# LDA with original participant data\n",
    "x_original3 = []\n",
    "x_original4 = []\n",
    "for s in stimuli_exp3:\n",
    "    schema_profile = exp_3_df[exp_3_df['Stimulus'] == s].iloc[:, 1:6].values[0].tolist()\n",
    "    x_original3.append(schema_profile)\n",
    "for s in stimuli_exp4:\n",
    "    schema_profile = exp_4_df[exp_4_df['Stimulus'] == s].iloc[:, 1:6].values[0].tolist()\n",
    "    x_original4.append(schema_profile)\n",
    "\n",
    "# LDA with participant data with IS\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(x_original3, y)\n",
    "y_pred3 = clf.predict(x_original3)\n",
    "print('accuracy original exp3:', accuracy_score(y_true=y, y_pred=y_pred3))\n",
    "\n",
    "clf.fit(x_original4, y)\n",
    "y_pred4 = clf.predict(x_original4)\n",
    "print('accuracy original exp4:', accuracy_score(y_true=y, y_pred=y_pred4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be at attention\n",
      "[3.4, 5.1, 4.53, 3.3, 3.5]\n",
      "\n",
      "be distinguished in several sports\n",
      "[2.2, 3.0, 4.43, 3.73, 4.67]\n",
      "\n",
      "to hold firm\n",
      "[5.47, 3.67, 4.73, 3.3, 4.0]\n",
      "\n",
      "don't allow such treatment\n",
      "[5.9, 2.6, 3.03, 3.13, 4.03]\n",
      "\n",
      "to pass the test of time\n",
      "[4.03, 2.4, 3.4, 2.73, 4.2]\n",
      "\n",
      "united we are strong\n",
      "[4.33, 3.13, 4.93, 4.27, 5.73]\n",
      "\n",
      "we are backed up by 30 years experience\n",
      "[2.5, 2.73, 3.0, 3.13, 5.2]\n",
      "\n",
      "let the issue remain as is\n",
      "[3.37, 2.47, 2.97, 2.47, 2.87]\n",
      "\n",
      "leave the mixture undisturbed\n",
      "[2.97, 2.43, 3.6, 2.6, 2.33]\n",
      "\n",
      "have a dale with someone who didn 't show up\n",
      "[3.93, 2.8, 2.27, 3.87, 4.23]\n",
      "\n",
      "he measures six-foot nine\n",
      "[1.6, 5.73, 2.73, 2.3, 2.4]\n",
      "\n",
      "the clock is on the mantle\n",
      "[1.17, 3.23, 3.6, 2.77, 3.1]\n",
      "\n",
      "one-night fling\n",
      "[2.7, 2.03, 2.1, 3.13, 3.43]\n",
      "\n",
      "to be in the position to make a profit\n",
      "[2.03, 2.73, 3.2, 4.27, 3.9]\n",
      "\n",
      "to be in someone else's shoes\n",
      "[2.57, 2.63, 2.1, 4.13, 4.67]\n",
      "\n",
      "on the witness platform\n",
      "[3.17, 3.4, 2.6, 4.83, 4.1]\n",
      "\n",
      "be in aw\n",
      "[2.23, 2.47, 2.57, 3.43, 4.37]\n",
      "\n",
      "the police told them to get back\n",
      "[5.43, 2.37, 2.47, 4.23, 4.73]\n",
      "\n",
      "support your man\n",
      "[2.53, 3.53, 3.47, 3.83, 3.83]\n",
      "\n",
      "the engine can't endure the constant wear\n",
      "[4.6, 2.4, 2.77, 3.23, 4.13]\n",
      "\n",
      "to be on shaky ground\n",
      "[4.6, 3.47, 5.33, 3.2, 3.77]\n",
      "\n",
      "to be accused\n",
      "[4.8, 2.13, 2.23, 4.47, 4.43]\n",
      "\n",
      "the house is in the clearing\n",
      "[1.4, 2.53, 2.27, 4.83, 2.8]\n",
      "\n",
      "the barometer is at 30 inches\n",
      "[2.3, 5.03, 2.7, 2.87, 3.1]\n",
      "\n",
      "as the matter now exists\n",
      "[2.3, 2.4, 2.43, 2.7, 3.7]\n",
      "\n",
      "the part represents the whole\n",
      "[1.87, 2.33, 3.23, 4.47, 4.67]\n",
      "\n",
      "it conforms with reason\n",
      "[2.47, 1.97, 2.57, 3.1, 3.57]\n",
      "\n",
      "they did nothing but hang around\n",
      "[2.53, 2.8, 2.43, 3.27, 2.9]\n",
      "\n",
      "to face great odds\n",
      "[5.7, 3.07, 3.2, 3.97, 4.33]\n",
      "\n",
      "a roaring ovation\n",
      "[2.63, 4.13, 2.73, 4.83, 5.43]\n",
      "\n",
      "the boss always hovers over me\n",
      "[4.37, 3.9, 2.7, 4.4, 3.93]\n",
      "\n",
      "he remains committed\n",
      "[3.56, 3.21, 2.12, 3.01, 3.66]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_original4)):\n",
    "    print(stimuli_exp4[i])\n",
    "    print(x_original4[i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stand at attention\n",
      "[4.0, 6.08, 5.0, 3.08, 2.08]\n",
      "\n",
      "stand out in several sports\n",
      "[2.0, 3.54, 2.83, 5.04, 3.42]\n",
      "\n",
      "to stand firm\n",
      "[6.21, 4.13, 5.04, 3.75, 2.83]\n",
      "\n",
      "don't stand for such treatment\n",
      "[5.54, 2.21, 3.04, 3.13, 3.08]\n",
      "\n",
      "to stand the test of time\n",
      "[4.88, 2.38, 3.92, 3.0, 4.08]\n",
      "\n",
      "united we stand\n",
      "[4.79, 4.21, 4.25, 4.78, 6.33]\n",
      "\n",
      "we stand on 30 years of experience\n",
      "[2.46, 2.63, 2.92, 3.43, 4.58]\n",
      "\n",
      "let the issue stand\n",
      "[2.83, 1.92, 2.08, 3.04, 2.96]\n",
      "\n",
      "let the mixture stand\n",
      "[1.54, 2.08, 3.17, 1.88, 2.0]\n",
      "\n",
      "get stood up for a date\n",
      "[1.83, 3.17, 3.04, 2.29, 2.17]\n",
      "\n",
      "he stands six-foot nine\n",
      "[2.29, 6.5, 3.54, 1.96, 2.0]\n",
      "\n",
      "the clock stands on the mantle\n",
      "[2.0, 4.38, 4.46, 2.13, 2.42]\n",
      "\n",
      "one-night stand\n",
      "[1.63, 1.46, 1.29, 2.17, 3.04]\n",
      "\n",
      "to stand to profit\n",
      "[2.04, 1.75, 1.79, 1.74, 3.54]\n",
      "\n",
      "to stand in someone else's shoes\n",
      "[2.25, 3.58, 2.96, 4.13, 4.7]\n",
      "\n",
      "on the witness stand\n",
      "[1.83, 2.08, 1.5, 3.63, 2.96]\n",
      "\n",
      "stand in awe\n",
      "[2.33, 3.75, 3.29, 3.65, 3.5]\n",
      "\n",
      "the police told them to stand back\n",
      "[3.63, 3.42, 2.17, 3.46, 2.74]\n",
      "\n",
      "stand by your man\n",
      "[3.0, 3.79, 2.79, 3.46, 4.74]\n",
      "\n",
      "the engine can't stand the constant wear\n",
      "[4.88, 1.33, 1.83, 1.58, 3.5]\n",
      "\n",
      "stand on shaky ground\n",
      "[4.63, 3.92, 6.04, 2.71, 3.29]\n",
      "\n",
      "to stand accused\n",
      "[3.5, 2.29, 2.0, 3.63, 3.54]\n",
      "\n",
      "the house stands in the clearing\n",
      "[1.83, 4.63, 3.5, 4.08, 3.17]\n",
      "\n",
      "the barometer stands at 30 inches\n",
      "[1.83, 4.71, 3.38, 1.46, 3.13]\n",
      "\n",
      "as the matter now stands\n",
      "[2.42, 1.88, 2.96, 2.63, 3.25]\n",
      "\n",
      "the part stands for the whole\n",
      "[2.29, 1.83, 1.96, 3.87, 2.42]\n",
      "\n",
      "it stands to reason\n",
      "[2.25, 1.96, 2.63, 2.42, 3.63]\n",
      "\n",
      "they did nothing but stand around\n",
      "[1.92, 4.71, 3.54, 2.13, 2.21]\n",
      "\n",
      "to stand against great odds\n",
      "[6.46, 3.08, 4.13, 5.13, 4.25]\n",
      "\n",
      "a standing ovation\n",
      "[1.96, 5.0, 3.17, 3.5, 3.5]\n",
      "\n",
      "the boss always stands over me\n",
      "[3.58, 4.71, 2.75, 4.04, 3.75]\n",
      "\n",
      "he stands committed\n",
      "[4.12, 3.66, 3.55, 3.12, 3.29]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_original3)):\n",
    "    print(stimuli_exp3[i])\n",
    "    print(x_original3[i])\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
